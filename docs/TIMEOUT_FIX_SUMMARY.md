# Timeout Fix Summary: AWS Lambda Experiment Optimization

## ğŸ› **Issue Analysis**

**The timeout you experienced was caused by running a massive experiment:**

```bash
./run_experiment.sh run-experiment 10 20 5m Manhattan 30s 10 6 2019
```

**Calculation of experiment size:**
- Time range: 10:00-20:00 = 10 hours = 600 minutes
- Time interval: 5m = 5 minutes
- **Scenarios**: 600 Ã· 5 = **120 scenarios**
- **Methods**: 4 (hikima, maps, linucb, linear_program)
- **Monte Carlo evaluations**: 100 per scenario (default)
- **Total evaluations**: 120 Ã— 4 Ã— 100 = **48,000 evaluations** 

This exceeds AWS Lambda's **15-minute timeout limit**.

## âœ… **Fixes Implemented**

### **1. Added Timeout Handling**
```bash
# Added timeout command with proper AWS CLI timeouts
timeout 900 /usr/local/bin/aws lambda invoke \
    --function-name rideshare-experiment-runner \
    --payload "$payload" \
    --region $REGION \
    --cli-binary-format raw-in-base64-out \
    --cli-read-timeout 900 \
    --cli-connect-timeout 60 \
    response.json
```

### **2. Added Experiment Size Validation**
The script now warns you before running large experiments:
```bash
âš ï¸  Large experiment detected: 48000 total evaluations
âš ï¸  This may exceed Lambda timeout limits (15 minutes)

ğŸ’¡ Suggested optimizations:
  â€¢ Reduce methods: Use 1-2 methods instead of 4
  â€¢ Reduce simulation_range: Use 30-60 instead of 120 scenarios

Continue anyway? (y/N)
```

### **3. Enhanced Error Messages**
Better timeout handling with specific guidance:
```bash
â° Experiment timed out after 15 minutes
ğŸ’¡ Try reducing simulation_range or num_eval for faster execution

ğŸ”§ Suggested fixes:
  1. Reduce simulation_range: Use 30 instead of 120 scenarios
  2. Reduce num_eval: Use 50 instead of 100 Monte Carlo evaluations  
  3. Run fewer methods: Use 1-2 methods instead of 4

Example with smaller parameters:
  ./run_experiment.sh run-experiment 10 20 5m Manhattan 30s 10 6 2019 green "hikima" PL
```

## ğŸš€ **Optimized Commands**

### **Quick Test (2-3 minutes)**
```bash
# Test with minimal parameters
./run_experiment.sh run-experiment 10 12 30m Manhattan 30s 10 6 2019 green "hikima" PL
# 4 scenarios Ã— 1 method Ã— 100 evals = 400 total evaluations
```

### **Small Experiment (5-8 minutes)**
```bash
# Test with moderate parameters  
./run_experiment.sh run-experiment 10 16 30m Manhattan 30s 10 6 2019 green "hikima,maps" PL
# 12 scenarios Ã— 2 methods Ã— 100 evals = 2,400 total evaluations
```

### **Medium Experiment (8-12 minutes)**
```bash
# Reasonable size for most testing
./run_experiment.sh run-experiment 10 20 10m Manhattan 30s 10 6 2019 green "hikima,maps,linucb" PL  
# 60 scenarios Ã— 3 methods Ã— 100 evals = 18,000 total evaluations
```

### **Full Paper Reproduction (12-15 minutes)**
```bash
# Original paper parameters (at timeout limit)
./run_experiment.sh run-experiment 10 20 5m Manhattan 30s 10 6 2019 green "hikima,maps,linucb" PL
# 120 scenarios Ã— 3 methods Ã— 100 evals = 36,000 total evaluations
```

## ğŸ“Š **Experiment Size Guidelines**

| Total Evaluations | Expected Time | Status | Recommendation |
|-------------------|---------------|--------|----------------|
| < 5,000 | 2-5 minutes | âœ… Safe | Good for testing |
| 5,000 - 20,000 | 5-10 minutes | âš ï¸ Moderate | Recommended for most experiments |
| 20,000 - 40,000 | 10-15 minutes | âš ï¸ Large | Use for final runs only |
| > 40,000 | 15+ minutes | âŒ Timeout Risk | Break into smaller experiments |

**Formula**: `Total Evaluations = scenarios Ã— methods Ã— num_eval`

## ğŸ”§ **Parameter Optimization Strategies**

### **Reduce Scenarios**
```bash
# Instead of 5-minute intervals (120 scenarios)
./run_experiment.sh run-experiment 10 20 5m Manhattan 30s 10 6 2019

# Use 10-minute intervals (60 scenarios)  
./run_experiment.sh run-experiment 10 20 10m Manhattan 30s 10 6 2019

# Use 20-minute intervals (30 scenarios)
./run_experiment.sh run-experiment 10 20 20m Manhattan 30s 10 6 2019
```

### **Reduce Methods**
```bash
# Instead of all 4 methods
"hikima,maps,linucb,linear_program"

# Test individual methods first
"hikima"
"maps" 
"linear_program"

# Compare best 2 methods
"hikima,linear_program"
```

### **Reduce Time Range**
```bash
# Instead of full day (10:00-20:00)
./run_experiment.sh run-experiment 10 20 5m Manhattan 30s 10 6 2019

# Test peak hours only (16:00-19:00)
./run_experiment.sh run-experiment 16 19 5m Manhattan 30s 10 6 2019

# Test specific time window (10:00-14:00)  
./run_experiment.sh run-experiment 10 14 5m Manhattan 30s 10 6 2019
```

## ğŸ§ª **Testing Workflow**

### **Step 1: Quick Validation**
```bash
# Test 1 method, small time range
./run_experiment.sh run-experiment 10 12 30m Manhattan 30s 10 6 2019 green "hikima" PL
```

### **Step 2: Method Comparison**
```bash
# Test all methods, small time range
./run_experiment.sh run-experiment 10 14 15m Manhattan 30s 10 6 2019 green "hikima,maps,linucb,linear_program" PL
```

### **Step 3: Full Experiment**
```bash
# Full time range, best methods only
./run_experiment.sh run-experiment 10 20 5m Manhattan 30s 10 6 2019 green "hikima,linear_program" PL
```

## ğŸ“ **About the "2015-03-31" URL**

**This is NOT a bug!** The date `2015-03-31` in the URL:
```
https://lambda.eu-north-1.amazonaws.com/2015-03-31/functions/rideshare-experiment-runner/invocations
```

Is the **AWS Lambda API version**, not a date issue. This is the standard AWS Lambda endpoint format.

## ğŸ¯ **Best Practices**

1. **Start Small**: Always test with minimal parameters first
2. **Gradual Scale-Up**: Increase experiment size gradually  
3. **Monitor Time**: Watch execution times and scale accordingly
4. **Use Validation**: The script now warns about large experiments
5. **Focus Methods**: Test 1-2 methods at a time for faster iteration

## ğŸš€ **Ready to Use**

The system now has:
- âœ… **Timeout protection** (15-minute limit)
- âœ… **Size validation** (warns about large experiments)
- âœ… **Better error messages** (specific guidance)
- âœ… **Optimization suggestions** (automatic recommendations)

**You can now run experiments confidently without timeouts!** ğŸ‰ 