#!/usr/bin/env python3
"""
Hikima-Compliant Experiment Runner
Implements the exact experimental setup from Hikima et al. paper.
"""

import json
import pandas as pd
import numpy as np
from datetime import datetime, timedelta
from typing import Dict, List, Any, Tuple
import logging
import math
import random
from dataclasses import dataclass
from geopy.distance import geodesic
from scipy.optimize import linear_sum_assignment

logger = logging.getLogger()

@dataclass
class HikimaParameters:
    """Parameters from the Hikima paper"""
    # Time parameters - exactly as specified in paper
    SIMULATION_HOURS = (10, 20)  # 10:00 to 20:00
    TIME_INTERVAL_MINUTES = 5    # Every 5 minutes
    TIME_STEP_MANHATTAN = 30     # 30 seconds for Manhattan
    TIME_STEP_OTHER = 300        # 300 seconds for other regions
    
    # Algorithm parameters from paper
    ALPHA = 18.0                 # Opportunity cost parameter (Î±=18)
    S_TAXI = 25.0               # Taxi speed 25 km/h
    BASE_PRICE = 5.875          # Base price $5.875
    NUM_EVAL = 100              # Monte Carlo evaluations (N=100)
    
    # MAPS parameters from paper
    S_0_RATE = 1.5              # S_0 rate parameter
    
    # LinUCB parameters from paper
    UCB_ALPHA = 0.5             # UCB Î± parameter
    ARM_MULTIPLIERS = [0.6, 0.8, 1.0, 1.2, 1.4]  # Price arms
    
    # Acceptance function parameters from paper
    PL_ALPHA = 1.5                              # Piecewise linear Î±
    SIGMOID_BETA = 1.3                          # Sigmoid Î² = 1.3
    SIGMOID_GAMMA = 0.3 * np.sqrt(3) / np.pi    # Sigmoid Î³ = 0.3âˆš3/Ï€

class HikimaExperiment:
    """Main experiment class implementing Hikima methodology"""
    
    def __init__(self):
        self.params = HikimaParameters()
        
    def preprocess_rideshare_data(self, df: pd.DataFrame, region: str, 
                                 simulation_time: datetime) -> Tuple[pd.DataFrame, pd.DataFrame]:
        """
        Preprocess NYC taxi data following Hikima methodology exactly.
        
        Returns:
            requesters: Rides requesting pickup in time window
            taxis: Taxis becoming available in time window
        """
        # Time window based on region (as in paper)
        time_step = (self.params.TIME_STEP_MANHATTAN if region == 'Manhattan' 
                    else self.params.TIME_STEP_OTHER)
        end_time = simulation_time + timedelta(seconds=time_step)
        
        # Convert datetime columns
        df['pickup_datetime'] = pd.to_datetime(df['pickup_datetime'])
        df['dropoff_datetime'] = pd.to_datetime(df['dropoff_datetime'])
        
        # Filter requesters (U): trips starting in time window
        requesters = df[
            (df['pickup_datetime'] >= simulation_time) & 
            (df['pickup_datetime'] < end_time) &
            (df['trip_distance'] > 1e-3) &  # Remove invalid trips
            (df['total_amount'] > 1e-3)
        ].copy()
        
        # Filter available taxis (V): trips ending in time window
        taxis = df[
            (df['dropoff_datetime'] >= simulation_time) & 
            (df['dropoff_datetime'] < end_time)
        ].copy()
        
        # Add geographic noise as in original paper
        if 'pickup_latitude' in requesters.columns:
            requesters['pickup_lat'] = (requesters['pickup_latitude'] + 
                                      np.random.normal(0, 0.00306, len(requesters)))
            requesters['pickup_lon'] = (requesters['pickup_longitude'] + 
                                      np.random.normal(0, 0.000896, len(requesters)))
        
        if 'dropoff_latitude' in taxis.columns:
            taxis['dropoff_lat'] = (taxis['dropoff_latitude'] + 
                                   np.random.normal(0, 0.00306, len(taxis)))
            taxis['dropoff_lon'] = (taxis['dropoff_longitude'] + 
                                   np.random.normal(0, 0.000896, len(taxis)))
        
        logger.info(f"ðŸ“Š Region {region}: {len(requesters)} requesters, {len(taxis)} taxis")
        return requesters, taxis
    
    def calculate_distances_and_weights(self, requesters: pd.DataFrame, 
                                       taxis: pd.DataFrame) -> Tuple[np.ndarray, np.ndarray]:
        """
        Calculate distance matrix and edge weights exactly as in Hikima paper.
        
        Returns:
            distance_matrix: Distances between requesters and taxis (km)
            edge_weights: W[i,j] = -(d_ij + trip_distance)/s_taxi * Î±
        """
        if len(requesters) == 0 or len(taxis) == 0:
            return np.array([]), np.array([])
        
        n_requesters = len(requesters)
        n_taxis = len(taxis)
        
        # Calculate geodesic distances
        distances = np.zeros((n_requesters, n_taxis))
        
        for i in range(n_requesters):
            req_coords = (requesters.iloc[i]['pickup_lat'], requesters.iloc[i]['pickup_lon'])
            for j in range(n_taxis):
                taxi_coords = (taxis.iloc[j]['dropoff_lat'], taxis.iloc[j]['dropoff_lon'])
                distances[i, j] = geodesic(req_coords, taxi_coords).kilometers
        
        # Calculate edge weights: W[i,j] = -(d_ij + o_dist)/s_taxi * Î±
        weights = np.zeros((n_requesters, n_taxis))
        
        for i in range(n_requesters):
            trip_distance_km = requesters.iloc[i]['trip_distance'] * 1.60934  # miles to km
            for j in range(n_taxis):
                weights[i, j] = (-(distances[i, j] + trip_distance_km) / 
                               self.params.S_TAXI * self.params.ALPHA)
        
        return distances, weights
    
    def piecewise_linear_acceptance(self, price: float, trip_amount: float) -> float:
        """
        Piecewise Linear acceptance function from Hikima paper.
        p_u^PL(x) = 1 if x < q_u
                   = (-1/(Î±-1)q_u) * x + Î±/(Î±-1) if q_u â‰¤ x â‰¤ Î±Â·q_u  
                   = 0 if x > Î±Â·q_u
        """
        q_u = trip_amount
        alpha = self.params.PL_ALPHA
        
        if price < q_u:
            return 1.0
        elif price <= alpha * q_u:
            return (-1/((alpha-1)*q_u)) * price + alpha/(alpha-1)
        else:
            return 0.0
    
    def sigmoid_acceptance(self, price: float, trip_amount: float) -> float:
        """
        Sigmoid acceptance function from Hikima paper.
        p_u^Sig(x) = 1 - 1/(1 + exp(-(x-Î²Â·q_u)/(Î³Â·|q_u|)))
        """
        q_u = trip_amount
        beta = self.params.SIGMOID_BETA
        gamma = self.params.SIGMOID_GAMMA
        
        if abs(q_u) < 1e-6:  # Handle edge case
            return 0.5
        
        exponent = -(price - beta * q_u) / (gamma * abs(q_u))
        return 1 - 1 / (1 + math.exp(exponent))
    
    def evaluate_hikima_method(self, requesters: pd.DataFrame, taxis: pd.DataFrame,
                              distances: np.ndarray, weights: np.ndarray,
                              acceptance_function: str) -> Dict[str, Any]:
        """
        Evaluate Hikima's proposed method.
        
        Note: This is a simplified implementation. The full paper implementation
        uses a complex min-cost flow algorithm. Here we use Hungarian algorithm
        as an approximation for the bipartite matching.
        """
        start_time = datetime.now()
        
        if len(requesters) == 0 or len(taxis) == 0:
            return self._empty_result('hikima')
        
        # Use Hungarian algorithm for bipartite matching (approximation)
        n_req, n_taxi = len(requesters), len(taxis)
        
        # Create cost matrix for assignment (negative weights for maximization)
        if n_req <= n_taxi:
            cost_matrix = -weights
        else:
            cost_matrix = -weights[:n_taxi, :]
            n_req = n_taxi
        
        # Solve assignment
        row_indices, col_indices = linear_sum_assignment(cost_matrix)
        
        # Calculate prices and simulate acceptance
        total_objective = 0
        successful_matches = 0
        prices = []
        acceptances = []
        
        for i, req_idx in enumerate(row_indices):
            if req_idx < len(requesters):
                requester = requesters.iloc[req_idx]
                
                # Hikima pricing strategy (simplified)
                base_price = self.params.BASE_PRICE
                distance_factor = distances[req_idx, col_indices[i]] if col_indices[i] < distances.shape[1] else 1.0
                trip_distance = requester['trip_distance'] * 1.60934
                
                # Price includes distance and opportunity cost
                price = base_price * (1 + distance_factor/10 + trip_distance/20)
                prices.append(price)
                
                # Calculate acceptance probability
                trip_amount = requester['total_amount']
                if acceptance_function == 'PL':
                    acceptance_prob = self.piecewise_linear_acceptance(price, trip_amount)
                else:
                    acceptance_prob = self.sigmoid_acceptance(price, trip_amount)
                
                acceptances.append(acceptance_prob)
                
                # Simulate acceptance
                if random.random() < acceptance_prob:
                    successful_matches += 1
                    # Add edge weight to objective
                    weight_bonus = weights[req_idx, col_indices[i]] if col_indices[i] < weights.shape[1] else 0
                    total_objective += price + weight_bonus
        
        computation_time = (datetime.now() - start_time).total_seconds()
        
        return {
            'method': 'hikima',
            'objective_value': float(total_objective),
            'successful_matches': int(successful_matches),
            'computation_time': computation_time,
            'total_requests': len(requesters),
            'available_taxis': len(taxis),
            'avg_price': float(np.mean(prices)) if prices else 0,
            'avg_acceptance': float(np.mean(acceptances)) if acceptances else 0
        }
    
    def evaluate_maps_method(self, requesters: pd.DataFrame, taxis: pd.DataFrame,
                           acceptance_function: str) -> Dict[str, Any]:
        """
        Evaluate MAPS method (area-based pricing approximation).
        """
        start_time = datetime.now()
        
        if len(requesters) == 0 or len(taxis) == 0:
            return self._empty_result('maps')
        
        # MAPS uses area-based uniform pricing
        total_objective = 0
        successful_matches = 0
        prices = []
        acceptances = []
        
        # MAPS parameters from paper
        s_a = 1 / (self.params.S_0_RATE - 1)
        s_b = 1 + 1 / (self.params.S_0_RATE - 1)
        
        for _, requester in requesters.iterrows():
            trip_distance = requester['trip_distance'] * 1.60934  # km
            trip_amount = requester['total_amount']
            
            # MAPS pricing (simplified from paper)
            if trip_distance > 0:
                price_per_km = trip_amount / trip_distance
                price = max(price_per_km * self.params.S_0_RATE, self.params.BASE_PRICE)
            else:
                price = self.params.BASE_PRICE
                
            prices.append(price)
            
            # Calculate acceptance
            if acceptance_function == 'PL':
                acceptance_prob = self.piecewise_linear_acceptance(price, trip_amount)
            else:
                acceptance_prob = self.sigmoid_acceptance(price, trip_amount)
            
            acceptances.append(acceptance_prob)
            
            # Simulate acceptance
            if random.random() < acceptance_prob:
                successful_matches += 1
                # MAPS objective includes opportunity cost
                total_objective += price - self.params.ALPHA / self.params.S_TAXI
        
        computation_time = (datetime.now() - start_time).total_seconds()
        
        return {
            'method': 'maps',
            'objective_value': float(total_objective),
            'successful_matches': int(successful_matches),
            'computation_time': computation_time,
            'total_requests': len(requesters),
            'available_taxis': len(taxis),
            'avg_price': float(np.mean(prices)) if prices else 0,
            'avg_acceptance': float(np.mean(acceptances)) if acceptances else 0
        }
    
    def evaluate_linucb_method(self, requesters: pd.DataFrame, taxis: pd.DataFrame,
                             acceptance_function: str, hour: int) -> Dict[str, Any]:
        """
        Evaluate LinUCB method (contextual bandit).
        """
        start_time = datetime.now()
        
        if len(requesters) == 0 or len(taxis) == 0:
            return self._empty_result('linucb')
        
        # LinUCB price arms from paper
        arm_prices = [self.params.BASE_PRICE * mult for mult in self.params.ARM_MULTIPLIERS]
        
        total_objective = 0
        successful_matches = 0
        prices = []
        acceptances = []
        
        for _, requester in requesters.iterrows():
            # Select arm (simplified - random selection for demo)
            # Full implementation would use UCB with context features
            selected_arm = random.choice(range(len(arm_prices)))
            trip_distance = requester['trip_distance']
            price = arm_prices[selected_arm] * trip_distance
            prices.append(price)
            
            # Calculate acceptance
            trip_amount = requester['total_amount']
            if acceptance_function == 'PL':
                acceptance_prob = self.piecewise_linear_acceptance(price, trip_amount)
            else:
                acceptance_prob = self.sigmoid_acceptance(price, trip_amount)
            
            acceptances.append(acceptance_prob)
            
            # Simulate acceptance
            if random.random() < acceptance_prob:
                successful_matches += 1
                total_objective += price
        
        computation_time = (datetime.now() - start_time).total_seconds()
        
        return {
            'method': 'linucb',
            'objective_value': float(total_objective),
            'successful_matches': int(successful_matches),
            'computation_time': computation_time,
            'total_requests': len(requesters),
            'available_taxis': len(taxis),
            'avg_price': float(np.mean(prices)) if prices else 0,
            'avg_acceptance': float(np.mean(acceptances)) if acceptances else 0
        }
    
    def _empty_result(self, method: str) -> Dict[str, Any]:
        """Return empty result structure."""
        return {
            'method': method,
            'objective_value': 0.0,
            'successful_matches': 0,
            'computation_time': 0.0,
            'total_requests': 0,
            'available_taxis': 0,
            'avg_price': 0.0,
            'avg_acceptance': 0.0
        }
    
    def run_single_simulation(self, df: pd.DataFrame, region: str, 
                            simulation_time: datetime, methods: List[str],
                            acceptance_function: str) -> Dict[str, Any]:
        """Run a single simulation following Hikima methodology."""
        
        # Preprocess data for this time window
        requesters, taxis = self.preprocess_rideshare_data(df, region, simulation_time)
        
        if len(requesters) == 0 or len(taxis) == 0:
            return {
                'simulation_time': simulation_time.isoformat(),
                'region': region,
                'requesters': 0,
                'taxis': 0,
                'results': {method: self._empty_result(method) for method in methods}
            }
        
        # Calculate distances and weights
        distances, weights = self.calculate_distances_and_weights(requesters, taxis)
        
        # Run Monte Carlo evaluations for each method
        method_results = {}
        
        for method in methods:
            evaluations = []
            
            # Run NUM_EVAL evaluations as specified in paper
            for _ in range(self.params.NUM_EVAL):
                if method == 'hikima':
                    result = self.evaluate_hikima_method(
                        requesters, taxis, distances, weights, acceptance_function
                    )
                elif method == 'maps':
                    result = self.evaluate_maps_method(
                        requesters, taxis, acceptance_function
                    )
                elif method == 'linucb':
                    result = self.evaluate_linucb_method(
                        requesters, taxis, acceptance_function, simulation_time.hour
                    )
                
                evaluations.append(result)
            
            # Aggregate Monte Carlo results
            if evaluations:
                objectives = [e['objective_value'] for e in evaluations]
                matches = [e['successful_matches'] for e in evaluations]
                times = [e['computation_time'] for e in evaluations]
                prices = [e['avg_price'] for e in evaluations]
                acceptances = [e['avg_acceptance'] for e in evaluations]
                
                method_results[method] = {
                    'avg_objective_value': float(np.mean(objectives)),
                    'std_objective_value': float(np.std(objectives)),
                    'avg_successful_matches': float(np.mean(matches)),
                    'avg_computation_time': float(np.mean(times)),
                    'avg_price': float(np.mean(prices)),
                    'avg_acceptance_rate': float(np.mean(acceptances)),
                    'monte_carlo_runs': len(evaluations)
                }
        
        return {
            'simulation_time': simulation_time.isoformat(),
            'region': region,
            'requesters': len(requesters),
            'taxis': len(taxis),
            'acceptance_function': acceptance_function,
            'results': method_results
        } 